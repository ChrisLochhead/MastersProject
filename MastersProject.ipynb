{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.0.1 (SDL 2.0.14, Python 3.6.10)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "import pygame\n",
    "\n",
    "import pygame_menu\n",
    "import pygame.freetype\n",
    "import sys\n",
    "import random\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "from gym import Env\n",
    "from gym.spaces import Discrete, Box\n",
    "\n",
    "\n",
    "from rl.agents import DQNAgent\n",
    "from rl.policy import BoltzmannQPolicy\n",
    "from rl.memory import SequentialMemory\n",
    "\n",
    "#from rl.agents import DQNAgent\n",
    "#from rl.memory import SequentialMemory\n",
    "from rl.policy import LinearAnnealedPolicy, EpsGreedyQPolicy\n",
    "\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Chris\\Documents\\MastersProject\\MastersProject\n",
      "C:\\Users\\Chris\\Documents\\MastersProject\\MastersProject\n",
      "C:\\Users\\Chris\\Documents\\MastersProject\\MastersProject\n",
      "C:\\Users\\Chris\\Documents\\MastersProject\\MastersProject\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(8, 0)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import os.path\n",
    "#os.chdir(r\"..\\\\\")\n",
    "#Import local modules\n",
    "print(os.getcwd())\n",
    "sys.path.append(os.getcwd())\n",
    "print(os.getcwd())\n",
    "#sys.path.append(r\"C:/Users/chris/OneDrive/Documents/Masters Project\")\n",
    "from ipynb.fs.full.Games.SpaceInvaders import Space_Invaders\n",
    "print(os.getcwd())\n",
    "from ipynb.fs.full.Games.Asteroids import Asteroids\n",
    "print(os.getcwd())\n",
    "pygame.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Custom_OpenAI_Env(Env):\n",
    "    def __init__(self, screen_width, screen_height, screen, surface, game, \n",
    "                 colour = False, action_space = Discrete(4)):\n",
    "        # Assign action and observation space\n",
    "        self.action_space = action_space\n",
    "        self.observation_space = Box(0, 255, shape=(1, screen_width, screen_height, ))\n",
    "\n",
    "        #Initialise the game\n",
    "        self.game = game\n",
    "\n",
    "        #Assign colour, get the initial game state and record it \n",
    "        self.colour = colour\n",
    "        self.state = self.game.get_state(colour = self.colour)\n",
    "        self.start_state = self.state\n",
    "        \n",
    "        #Get a reference to the surfaces used by pygame\n",
    "        self.surface = surface\n",
    "        self.screen = screen\n",
    "        print(\"initialisation complete\")\n",
    "        \n",
    "        self.delay = 1000\n",
    "        \n",
    "    def step(self, action):\n",
    "        # Apply action\n",
    "        self.game.execute_action(action)\n",
    "        #Call the update loop before getting the state\n",
    "        self.game.update()\n",
    "        self.state = self.game.get_state(colour = self.colour)\n",
    "        #Calculate step-based reward\n",
    "        reward = self.game.calculate_reward()\n",
    "        done = self.game.done\n",
    "        # Set placeholder for info\n",
    "        info = {}\n",
    "        # Return step information\n",
    "        return self.state, reward, done, info\n",
    "    \n",
    "    def render(self, mode):\n",
    "        self.game.render()\n",
    "        \n",
    "    def reset(self):\n",
    "        #Restart the game\n",
    "        self.state = self.start_state\n",
    "        self.game.reset()\n",
    "        return self.game.get_state()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Game menu class controlling the functionality of the entire framework\n",
    "class Game_Menu:\n",
    "\n",
    "    def __init__(self, width, height):\n",
    "        self.screen = None\n",
    "        self.menu = None\n",
    "        self.surface = None\n",
    "        self.game = None\n",
    "        self.icon_surface = None\n",
    "        \n",
    "        #Set standard network parameters\n",
    "        self.learning_rates = [0.1, 0.01, 0.001]\n",
    "        self.episodes = [1, 5, 10]\n",
    "        self.steps = [1000, 5000, 100000]\n",
    "\n",
    "        #Standard parameter indices\n",
    "        self.learning_rate = 0\n",
    "        self.episode = 0\n",
    "        self.step = 0\n",
    "        self.visualize = False\n",
    "\n",
    "        #Asteroid specific parameters\n",
    "        self.scales = [[800,600, 1.0], [300,300, 0.7], [150,150, 0.35]]\n",
    "        self.intensity_rates = [0.1, 0.5, 1.0]\n",
    "        self.player_speeds = [1, 1.5, 3]\n",
    "\n",
    "        #Scale, player speed and colour are common to both games\n",
    "        self.scale = 0\n",
    "        self.intensity = 0\n",
    "        self.player_speed = 0\n",
    "        self.homogenous_controls = False\n",
    "        self.colour = False\n",
    "        \n",
    "        #Space invaders specific parameters\n",
    "        self.enemy_speeds = [0.5, 1.0, 2.0]\n",
    "        self.enemy_speed = 0\n",
    "        \n",
    "        #Transfer mode \n",
    "        self.transfer = -1\n",
    "        \n",
    "        #Initialise pygame\n",
    "        pygame.display.init()\n",
    "        self.surface = pygame.display.set_mode((800, 600))\n",
    "        self.icon_surface = pygame.image.load(os.path.join(os.getcwd(), \"Dependencies/Resources\", \"Masterslogo.png\"))\n",
    "        pygame.display.set_icon(self.icon_surface)\n",
    "        pygame.display.set_caption(\"Master's Project\")\n",
    "        \n",
    "        #Start the main menu\n",
    "        self.main_menu()\n",
    "        \n",
    "    def main_menu(self):\n",
    "        \n",
    "        self.surface = pygame.display.set_mode((800, 600))\n",
    "        #Disable any menu if it exists\n",
    "        if self.menu:\n",
    "            self.menu.disable()\n",
    "        #Initialise the main menu interface\n",
    "        self.menu = pygame_menu.Menu(600, 800, 'Main Menu',\n",
    "                         theme=pygame_menu.themes.THEME_DARK)\n",
    "        self.menu.add_button('Space Invaders', self.start_space_invaders)\n",
    "        self.menu.add_button('Space Invaders - Training', self.set_game_mode)\n",
    "        self.menu.add_button('Asteroids', self.start_asteroids)\n",
    "        self.menu.add_button('Asteroids - Training', self.set_standard_parameters)\n",
    "        self.menu.add_button('Transfer Learning', self.transfer_menu)\n",
    "        self.menu.add_button('Quit', pygame_menu.events.EXIT)\n",
    "        \n",
    "        self.menu.mainloop(self.surface)\n",
    "\n",
    "    def transfer_menu(self):\n",
    "        #Transfer menu, always disable because this will never be the first\n",
    "        #menu created\n",
    "        self.menu.disable()\n",
    "        self.menu = pygame_menu.Menu(600, 800, 'Transfer Learning',\n",
    "                               theme=pygame_menu.themes.THEME_DARK)\n",
    "        self.menu.add_button('Space Invaders -> Asteroids', self.set_transfer_SA)\n",
    "        self.menu.add_button('Asteroids -> Space Invaders', self.set_transfer_AS)\n",
    "        self.menu.add_button('Back', self.main_menu)\n",
    "        \n",
    "        self.menu.mainloop(self.surface)\n",
    "    \n",
    "    #Common DQN network settings\n",
    "    def set_standard_param(self, arg, param):\n",
    "        #Learning rate \n",
    "        if param == 0:\n",
    "            print(\"changing learning rate\")\n",
    "            if self.learning_rate < 2:\n",
    "                self.learning_rate += 1\n",
    "            else:\n",
    "                self.learning_rate = 0\n",
    "        #Steps\n",
    "        elif param == 1:\n",
    "            if self.step < 2:\n",
    "                self.step += 1\n",
    "            else:\n",
    "                self.step = 0\n",
    "        #Episodes\n",
    "        elif param == 2:\n",
    "            if self.episode < 2:\n",
    "                self.episode += 1\n",
    "            else:\n",
    "                self.episode = 0\n",
    "        #Visualize\n",
    "        elif param == 3:\n",
    "            self.visualize = 1 if self.visualize == 0 else 1 \n",
    "            \n",
    "    def set_game_mode(self):\n",
    "        self.set_standard_parameters(1)\n",
    "    \n",
    "    #Set transfer mode: Space invaders to Asteroids\n",
    "    def set_transfer_SA(self):\n",
    "        self.transfer = 0\n",
    "        self.set_standard_parameters()\n",
    "        \n",
    "    #Set transfer mode: Asteroids to Space Invaders\n",
    "    def set_transfer_AS(self):\n",
    "        self.transfer = 1\n",
    "        self.set_standard_parameters(1)\n",
    "    \n",
    "    #Setup menu for standard network parameters\n",
    "    def set_standard_parameters(self, gamemode = 0):\n",
    "        print(\"standard params called\")\n",
    "        self.menu.disable()\n",
    "        self.gamemode = gamemode\n",
    "        self.menu = pygame_menu.Menu(600, 800, 'Select Variables',\n",
    "                               theme=pygame_menu.themes.THEME_DARK)\n",
    "\n",
    "        self.menu.add_selector('Learning rate :', [('1e-1', 0),\n",
    "                                                   ('1e-2', 0),\n",
    "                                                   ('1e-3', 0)],\n",
    "                                                   onchange=self.set_standard_param)\n",
    "        self.menu.add_selector('Steps :', [('1000', 1),\n",
    "                                           ('5000', 1),\n",
    "                                           ('10000', 1),],\n",
    "                                           onchange=self.set_standard_param)\n",
    "        self.menu.add_selector('Episodes: ', [('1', 2),\n",
    "                                           ('5', 2),\n",
    "                                           ('10', 2),],\n",
    "                                           onchange=self.set_standard_param)\n",
    "        self.menu.add_selector('Visualize', [('False', 3), ('True', 3)],\n",
    "                               onchange=self.set_standard_param)\n",
    "        self.menu.add_button('Back', self.main_menu)\n",
    "        \n",
    "        #Continue based on what game mode is selected\n",
    "        if gamemode == 0:\n",
    "            self.menu.add_button('Continue - Asteroids', self.set_asteroids_parameters)\n",
    "        else:\n",
    "            self.menu.add_button('Continue - Space Invaders', self.set_space_invaders_parameters)\n",
    "        \n",
    "        self.menu.mainloop(self.surface)\n",
    "    \n",
    "    def set_mode_parameter(self, arg, param):\n",
    "        #0 scale, 1 intensity, 2, player speed, 3 homo controls, 4 colours, 5 enemy speed\n",
    "        if param == 0:\n",
    "            self.scale += 1 if self.scale < 2 else 0\n",
    "        if param == 1:\n",
    "            self.intensity += 1 if self.intensity < 2 else 0        \n",
    "        if param == 2:\n",
    "            self.player_speed += 1 if self.player_speed < 2 else 0        \n",
    "        if param == 3:\n",
    "            self.homogenous_controls = True if self.homogenous_controls == False else False\n",
    "        if param == 4:\n",
    "            self.colour = True if self.colour == False else False\n",
    "        if param == 5:\n",
    "            self.enemy_speed += 1 if self.enemy_speed < 2 else 0\n",
    "            \n",
    "    #Menu for setting asteroids game mode specific parameters\n",
    "    def set_asteroids_parameters(self):\n",
    "        self.menu.disable()\n",
    "        self.menu = pygame_menu.Menu(600, 800, 'Select Gameplay Variables',\n",
    "                               theme=pygame_menu.themes.THEME_DARK)\n",
    "\n",
    "        self.menu.add_selector('Scale :', [('(800, 600)', 0), ('(400, 300)', 0),('(200, 150)', 0)],\n",
    "                               onchange=self.set_mode_parameter)\n",
    "        self.menu.add_selector('Intensity:', [('0.1', 1), ('0.5', 1),('1.0', 1)],\n",
    "                               onchange=self.set_mode_parameter)\n",
    "        self.menu.add_selector('Player Speed :', [('1', 2), ('1.5', 2),('3', 2)],\n",
    "                               onchange=self.set_mode_parameter)\n",
    "        self.menu.add_selector('Homogenous Controls: ', [('False', 3), ('True', 3)],\n",
    "                        onchange=self.set_mode_parameter)\n",
    "        self.menu.add_selector('Colour Input: ', [('False', 4), ('True', 4)],\n",
    "                        onchange=self.set_mode_parameter)\n",
    "        self.menu.add_button('Start Training', self.start_asteroids_training)\n",
    "        self.menu.add_button('Back', self.main_menu)\n",
    "        \n",
    "        self.menu.mainloop(self.surface)\n",
    "    \n",
    "    #Menu for setting Space invaders game mode specific parameters\n",
    "    def set_space_invaders_parameters(self):\n",
    "        self.menu.disable()\n",
    "        self.menu = pygame_menu.Menu(600, 800, 'Select Gameplay Variables',\n",
    "                               theme=pygame_menu.themes.THEME_DARK)\n",
    "\n",
    "        self.menu.add_selector('Scale :', [('(800, 600)', 0), ('(300, 300)', 0),\n",
    "                                          ('(150, 150)', 0)],\n",
    "                               onchange=self.set_mode_parameter)\n",
    "        self.menu.add_selector('Enemy Speed:', [('0.5', 5), ('1.0', 5),\n",
    "                                          ('2.0', 5)],\n",
    "                               onchange=self.set_mode_parameter)\n",
    "        self.menu.add_selector('Player Speed :', [('1', 2), ('1.5', 2),\n",
    "                                          ('3', 2)],\n",
    "                               onchange=self.set_mode_parameter)\n",
    "        self.menu.add_selector('Colour Input: ', [('False', 4), ('True', 4)],\n",
    "                        onchange=self.set_mode_parameter)\n",
    "        \n",
    "        self.menu.add_button('Start Training', self.start_space_invaders_training)\n",
    "        self.menu.add_button('Back', self.main_menu)\n",
    "        \n",
    "        self.menu.mainloop(self.surface)\n",
    "\n",
    "    #Start asteroids as a normal player\n",
    "    def start_asteroids(self):\n",
    "        self.game = Asteroids(800, 600, self.screen, self.surface, False, 0.125)\n",
    "\n",
    "    #Start space invaders as a normal player\n",
    "    def start_space_invaders(self):\n",
    "        self.game = Space_Invaders(800, 600,self.screen, self.surface, False, 1.0)\n",
    "        \n",
    "    def start_asteroids_training(self):\n",
    "        self.menu.disable()\n",
    "        print(\"starting asteroid training\")\n",
    "        training_game = Asteroids(self.scales[self.scale][0], self.scales[self.scale][1], \n",
    "                                  self.screen, self.surface, True, self.scales[self.scale][2], intensity = self.intensity_rates[self.intensity])\n",
    "        self.game = Custom_OpenAI_Env(self.scales[self.scale][0], self.scales[self.scale][1],\n",
    "                                      self.screen, self.surface, training_game, colour=self.colour)\n",
    "        self.build_model()\n",
    "        self.train_model()\n",
    "        self.save(self.model, \"asteroids\")\n",
    "        self.main_menu()\n",
    "    \n",
    "    def start_space_invaders_training(self):\n",
    "        self.menu.disable()\n",
    "        print(\"Starting space invaders training\")\n",
    "        training_game = Space_Invaders(self.scales[self.scale][0], self.scales[self.scale][1]\n",
    "                                       , self.screen, self.surface, True, self.scales[self.scale][2],\n",
    "                                      homogenous_controls = self.homogenous_controls)\n",
    "        \n",
    "        #Assign new action space based on homogenous control setting\n",
    "        action_space= Discrete(3)\n",
    "        if self.homogenous_controls:\n",
    "            action_space = Discrete(5)\n",
    "        self.game = Custom_OpenAI_Env(self.scales[self.scale][0], self.scales[self.scale][1],\n",
    "                                      self.screen, self.surface, training_game, colour=self.colour,\n",
    "                                     action_space = action_space)\n",
    "        self.build_model()\n",
    "        self.train_model()\n",
    "        self.save(self.model, \"space_invaders\")\n",
    "        self.main_menu()\n",
    "        \n",
    "    def build_model(self):\n",
    "        #Initialise state/action arrays\n",
    "        states = self.game.observation_space.shape\n",
    "        self.actions = self.game.action_space.n\n",
    "        \n",
    "        #Initialise the DRL model based on transfer setting\n",
    "        if self.transfer == -1:\n",
    "            self.model = self.build_network(states, self.actions)\n",
    "        elif self.transfer == 0:\n",
    "            print(\"loading space invaders original model.\")\n",
    "            if self.load(\"space_invaders\") != False:\n",
    "                self.model = self.load(\"space_invaders\")\n",
    "            else:\n",
    "                self.model = self.build_network(states, self.actions)\n",
    "        else:\n",
    "            print(\"loading asteroids original model\")\n",
    "            if self.load(\"asteroids\") != False:\n",
    "                self.model = self.load(\"asteroids\")\n",
    "            else:\n",
    "                self.model = self.build_network(states, self.actions)\n",
    "\n",
    "        \n",
    "    def train_model(self, metrics = ['mae'], episodes = 5, verbose = 1):\n",
    "        #Initialise the DQN agent\n",
    "        #Debug info\n",
    "        print(\"parameters: \", \"\\nlearning rate: \", self.learning_rates[self.learning_rate],\n",
    "             \"\\nepisodes: \",  self.episodes[self.episode],\n",
    "              \"\\nsteps: \", self.steps[self.step],\n",
    "              \"\\nvisualize: \", self.visualize,\n",
    "              \"\\nscale: \", self.scales[self.scale],\n",
    "              \"\\nintensity (asteroids only): \", self.intensity_rates[self.intensity],\n",
    "              \"\\nplayer speed : \", self.player_speeds[self.player_speed],\n",
    "              \"\\nhomogenous controls (space invaders only): \", self.homogenous_controls,\n",
    "              \"\\ncolour: \", self.colour)\n",
    "\n",
    "        \n",
    "        #Build and compile the DQN with network and policy settings\n",
    "        dqn = self.build_agent(self.model, self.actions)\n",
    "        dqn.compile(Adam(lr=self.learning_rates[self.learning_rate]), metrics=metrics)\n",
    "        \n",
    "        print(\"beginning training\")\n",
    "        #Fit with openAI gym\n",
    "        dqn.fit(self.game, nb_steps=self.steps[self.step], visualize=self.visualize, verbose=1)\n",
    "        \n",
    "        print(\"training complete\")\n",
    "        #Test with scores\n",
    "        scores = dqn.test(self.game, nb_episodes=self.episodes[self.episode], visualize=self.visualize)\n",
    "        print(np.mean(scores.history['episode_reward']))\n",
    "        \n",
    "    def save(self, model, name='default-model'):\n",
    "        #was dqn now model\n",
    "        model.save_weights(name + '.h5f', overwrite=True)\n",
    "        \n",
    "    def load(self, name):\n",
    "        #Load existing weights into the blank model \n",
    "        self.model = Sequential()\n",
    "        if os.path.isfile(name + '.h5f'): \n",
    "            return self.model.load_weights(name + '.h5f')\n",
    "        print(\"file not found, creating default model.\")\n",
    "        return False\n",
    "    \n",
    "    def build_network(self, states, actions):\n",
    "        model = Sequential()\n",
    "        #Convolutional layers\n",
    "        model.add(Conv2D(32, (10,10), activation='relu', input_shape=states, padding='same'))#(32, 32, 3)))\n",
    "        model.add(MaxPooling2D((10, 10), padding = 'same'))\n",
    "        model.add(Conv2D(32, (5,5), activation='relu', input_shape=states, padding='same'))#(32, 32, 3)))\n",
    "        model.add(MaxPooling2D((5, 5), padding = 'same'))\n",
    "        model.add(Flatten())\n",
    "        #Fully connected layers\n",
    "        model.add(Dense(100, activation='relu'))\n",
    "        model.add(Dense(100, activation='relu'))\n",
    "        model.add(Dense(self.actions, activation='linear'))\n",
    "        #Debug summary of the model built\n",
    "        print(model.summary())\n",
    "        return model\n",
    "\n",
    "    #Function to create DQN model \n",
    "    def build_agent(self, model, actions):\n",
    "        policy = BoltzmannQPolicy()\n",
    "        memory = SequentialMemory(limit=50000, window_length=1)\n",
    "        dqn = DQNAgent(model=model, memory=memory, policy=policy, \n",
    "                      nb_actions=actions, nb_steps_warmup=10, target_model_update=1e-2)\n",
    "        return dqn\n",
    "    \n",
    "    #Another function using eps greedy instead of boltzmann\n",
    "    def build_agent_reinforcement(model, actions):\n",
    "        policy = LinearAnnealedPolicy(EpsGreedyQPolicy(), attr='eps', value_max=1., value_min=.1, value_test=.2, nb_steps=10000)\n",
    "        memory = SequentialMemory(limit=1000, window_length=3)\n",
    "        dqn = DQNAgent(model=model, memory=memory, policy=policy,\n",
    "                      enable_dueling_network=True, dueling_type='avg', \n",
    "                       nb_actions=actions, nb_steps_warmup=1000\n",
    "                      )\n",
    "        return dqn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "standard params called\n",
      "changing learning rate\n",
      "Starting space invaders training\n",
      "initialisation complete\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 1, 150, 32)        480032    \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 1, 15, 32)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 1, 15, 32)         25632     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 1, 3, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 96)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 100)               9700      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 3)                 303       \n",
      "=================================================================\n",
      "Total params: 525,767\n",
      "Trainable params: 525,767\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "parameters:  \n",
      "learning rate:  0.01 \n",
      "episodes:  10 \n",
      "steps:  100000 \n",
      "visualize:  1 \n",
      "scale:  [150, 150, 0.35] \n",
      "intensity (asteroids only):  0.1 \n",
      "player speed :  1.5 \n",
      "homogenous controls (space invaders only):  False \n",
      "colour:  False\n",
      "beginning training\n",
      "Training for 100000 steps ...\n",
      "Interval 1 (0 steps performed)\n",
      "WARNING:tensorflow:From C:\\Users\\Chris\\anaconda3\\envs\\masters\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_v1.py:2070: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "    9/10000 [..............................] - ETA: 3:22 - reward: 0.0000e+00"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Chris\\anaconda3\\envs\\masters\\lib\\site-packages\\rl\\memory.py:40: UserWarning: Not enough entries to sample without replacement. Consider increasing your warm-up phase to avoid oversampling!\n",
      "  warnings.warn('Not enough entries to sample without replacement. Consider increasing your warm-up phase to avoid oversampling!')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 795s 80ms/step - reward: 0.0025\n",
      "26 episodes - episode_reward: 0.973 [0.200, 1.700] - loss: 9.474 - mae: 0.314 - mean_q: 0.472\n",
      "\n",
      "Interval 2 (10000 steps performed)\n",
      "10000/10000 [==============================] - 937s 94ms/step - reward: 0.0024\n",
      "21 episodes - episode_reward: 1.067 [0.100, 1.800] - loss: 0.000 - mae: 0.229 - mean_q: 0.344\n",
      "\n",
      "Interval 3 (20000 steps performed)\n",
      "10000/10000 [==============================] - 1146s 115ms/step - reward: 0.0026\n",
      "24 episodes - episode_reward: 1.083 [0.200, 1.800] - loss: 0.000 - mae: 0.181 - mean_q: 0.272\n",
      "\n",
      "Interval 4 (30000 steps performed)\n",
      "10000/10000 [==============================] - 1636s 164ms/step - reward: 0.0024\n",
      "23 episodes - episode_reward: 1.052 [0.200, 1.700] - loss: 0.000 - mae: 0.168 - mean_q: 0.253\n",
      "\n",
      "Interval 5 (40000 steps performed)\n",
      "10000/10000 [==============================] - 2612s 261ms/step - reward: 0.0021\n",
      "21 episodes - episode_reward: 1.043 [0.100, 1.600] - loss: 5.373 - mae: 0.735 - mean_q: 1.058\n",
      "\n",
      "Interval 6 (50000 steps performed)\n",
      "10000/10000 [==============================] - 3298s 330ms/step - reward: 0.0023\n",
      "20 episodes - episode_reward: 1.185 [0.200, 1.900] - loss: 0.001 - mae: 0.533 - mean_q: 0.799\n",
      "\n",
      "Interval 7 (60000 steps performed)\n",
      "10000/10000 [==============================] - 3556s 356ms/step - reward: 0.0024\n",
      "20 episodes - episode_reward: 1.135 [0.300, 1.800] - loss: 0.000 - mae: 0.276 - mean_q: 0.414\n",
      "\n",
      "Interval 8 (70000 steps performed)\n",
      "10000/10000 [==============================] - 3867s 387ms/step - reward: 0.0024\n",
      "21 episodes - episode_reward: 1.114 [0.200, 1.700] - loss: 0.000 - mae: 0.191 - mean_q: 0.287\n",
      "\n",
      "Interval 9 (80000 steps performed)\n",
      " 7746/10000 [======================>.......] - ETA: 15:10 - reward: 0.0025"
     ]
    }
   ],
   "source": [
    "Game = Game_Menu(800,600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
